{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daothuphuong98/COVID19-NER/blob/main/BiLSTM_CRF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wq9beqYrBWSH",
        "outputId": "730ccfbb-728b-4727-cc33-3963718f1871"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'PhoNER_COVID19'...\n",
            "remote: Enumerating objects: 58, done.\u001b[K\n",
            "remote: Counting objects: 100% (58/58), done.\u001b[K\n",
            "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
            "remote: Total 58 (delta 23), reused 41 (delta 18), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (58/58), 3.61 MiB | 8.93 MiB/s, done.\n",
            "Resolving deltas: 100% (23/23), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/VinAIResearch/PhoNER_COVID19.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xX-NSlpCu6kA",
        "outputId": "89fea708-a341-45f9-efc8-d1cc56092557"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
            "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-flnp0xi0\n",
            "  Running command git clone --filter=blob:none --quiet https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-flnp0xi0\n",
            "  warning: redirecting to https://github.com/keras-team/keras-contrib.git/\n",
            "  Resolved https://www.github.com/keras-team/keras-contrib.git to commit 3fc5ef709e061416f4bc8a92ca3750c824b5d2b0\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m864.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gensim==4.1.2\n",
            "  Downloading gensim-4.1.2.tar.gz (23.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from gensim==4.1.2) (1.23.5)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.10/dist-packages (from gensim==4.1.2) (1.11.4)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim==4.1.2) (6.4.0)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.2.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (23.2)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow_addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-contrib==2.0.8) (2.15.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.2.0)\n",
            "Building wheels for collected packages: gensim, seqeval, keras-contrib\n",
            "  Building wheel for gensim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gensim: filename=gensim-4.1.2-cp310-cp310-linux_x86_64.whl size=25996772 sha256=751e253b2c409c018ffe880a6fdb618d3b079304b3fa015695dff4ef2b65185e\n",
            "  Stored in directory: /root/.cache/pip/wheels/13/35/4e/dca2954de21981d0a137ff930239f0767403a617e32f19f04f\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=ed8fe872d9576bd5f7c758999d66a509eb70d00f4d8b8871777a9ca2cc32331a\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-py3-none-any.whl size=101055 sha256=50f65b426f0f91f97ae88d13d4a1b81abef0d13fbce15e2b82a1710066c83bde\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-5uqym1j2/wheels/74/d5/f7/0245af7ac33d5b0c2e095688649916e4bf9a8d6b3362a849f5\n",
            "Successfully built gensim seqeval keras-contrib\n",
            "Installing collected packages: typeguard, keras-contrib, tensorflow_addons, gensim, seqeval\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 4.3.2\n",
            "    Uninstalling gensim-4.3.2:\n",
            "      Successfully uninstalled gensim-4.3.2\n",
            "Successfully installed gensim-4.1.2 keras-contrib-2.0.8 seqeval-1.2.2 tensorflow_addons-0.23.0 typeguard-2.13.3\n"
          ]
        }
      ],
      "source": [
        "!pip install seqeval tensorflow_addons gensim==4.1.2 git+https://www.github.com/keras-team/keras-contrib.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLNMGG8lvEze",
        "outputId": "53822b30-6d06-4948-db5c-f07840bd3a8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n",
            "<ipython-input-3-69eaf9fad717>:19: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
            "  pd.set_option('display.max_colwidth', -1)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "import tensorflow.keras.layers as L\n",
        "from tensorflow_addons.text import crf_log_likelihood, crf_decode\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer, tokenizer_from_json\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, TimeDistributed, Input, BatchNormalization, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import initializers, Sequential\n",
        "from seqeval.metrics import f1_score, classification_report\n",
        "from keras_contrib.layers import CRF\n",
        "import tensorflow.keras.optimizers as Optimizer\n",
        "import plotly.express as px\n",
        "from gensim.models import FastText\n",
        "pd.set_option('display.max_colwidth', -1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QaW8nEUyQitV"
      },
      "source": [
        "#Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LO5gHyUfQhyZ"
      },
      "outputs": [],
      "source": [
        "def handle_file(link):\n",
        "    with open(link) as f:\n",
        "        contents = f.readlines()\n",
        "    idx_sentence, idx_arr, word, tag = 0, [], [], []\n",
        "    for line in contents:\n",
        "        arr_info = line.split(' ')\n",
        "        # print(arr_info)\n",
        "        if len(arr_info) == 1:\n",
        "            idx_sentence += 1\n",
        "            continue\n",
        "        word.append(arr_info[0])\n",
        "        tag.append(arr_info[1].replace('\\n', ''))\n",
        "        idx_arr.append(idx_sentence)\n",
        "    return pd.DataFrame(\n",
        "        data = {\n",
        "            'idx': idx_arr,\n",
        "            'word': word,\n",
        "            'tag': tag\n",
        "        }\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrybe1LBSyxL"
      },
      "outputs": [],
      "source": [
        "word_train_data = handle_file('/content/PhoNER_COVID19/data/word/train_word.conll')\n",
        "word_test_data = handle_file('/content/PhoNER_COVID19/data/word/test_word.conll')\n",
        "word_val_data = handle_file('/content/PhoNER_COVID19/data/word/dev_word.conll')\n",
        "\n",
        "word_train_data['word_process'] = word_train_data['word'].apply(lambda x: re.sub('[0-9]+', \"<NUM>\", x).lower())\n",
        "word_test_data['word_process'] = word_test_data['word'].apply(lambda x: re.sub('[0-9]+', \"<NUM>\", x).lower())\n",
        "word_val_data['word_process'] = word_val_data['word'].apply(lambda x: re.sub('[0-9]+', \"<NUM>\", x).lower())\n",
        "\n",
        "filter_string = '?!\"/\\{}().,'\n",
        "word_train_data = word_train_data[word_train_data['word_process'].apply(lambda x: x not in filter_string)]\n",
        "word_test_data = word_test_data[word_test_data['word_process'].apply(lambda x: x not in filter_string)]\n",
        "word_val_data = word_val_data[word_val_data['word_process'].apply(lambda x: x not in filter_string)]\n",
        "\n",
        "word_train_data_group = word_train_data.groupby('idx').agg({'word_process': ' '.join, 'word': ' '.join, 'tag': list})\n",
        "word_test_data_group = word_test_data.groupby('idx').agg({'word_process': ' '.join, 'word': ' '.join, 'tag': list})\n",
        "word_val_data_group = word_val_data.groupby('idx').agg({'word_process': ' '.join, 'word': ' '.join, 'tag': list})\n",
        "\n",
        "word_train_data_group['len_tag'] = word_train_data_group['tag'].apply(lambda x: len(x))\n",
        "word_val_data_group['len_tag'] = word_val_data_group['tag'].apply(lambda x: len(x))\n",
        "word_test_data_group['len_tag'] = word_test_data_group['tag'].apply(lambda x: len(x))\n",
        "\n",
        "# train_data_group = train_data_group[train_data_group['len_tag'] <= 55].reset_index()\n",
        "# val_data_group = val_data_group[val_data_group['len_tag'] <= 55].reset_index()\n",
        "# test_data_group = test_data_group[test_data_group['len_tag'] <= 55].reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4jG2m7Y4MAKN",
        "outputId": "3f47b061-23fa-47aa-d949-b8721776335a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                            word_process  \\\n",
              "idx                                                                                                        \n",
              "3752  bệnh_nhân <num> nữ <num> tuổi trú thị_trấn đông_phú huyện quế_sơn làm nghề buôn_bán                  \n",
              "4544  đây là em bé thứ ba dưới một tuổi tại việt_nam nhiễm ncov                                            \n",
              "4713  hai bệnh_nhân <num> <num> đi nhiều nơi gặp nhiều người trên địa_bàn tỉnh thừa_thiên_huế              \n",
              "5018  người ra viện cuối_cùng ở đà_nẵng là bệnh_nhân <num>                                                 \n",
              "130   ngày <num>/<num> bệnh_nhân đến trung_tâm y_tế huyện quế_sơn khám chụp phim điều_trị ngoại_trú        \n",
              "3261  ngày <num>/<num> mẫu bệnh_phẩm được viện vệ_sinh dịch_tễ trung_ương xét_nghiệm khẳng_định            \n",
              "4587  kết_quả xét_nghiệm ban_đầu có <num> mẫu âm_tính và nghi_ngờ dương_tính <num> mẫu                     \n",
              "887   ngày <num> - <num> bà khởi_phát bệnh                                                                 \n",
              "5026  ngày <num>/<num> anh được cách_ly tập_trung ngày <num>/<num> lấy mẫu xét_nghiệm kết_quả nghi nhiễm   \n",
              "4479  ông sơn đề_nghị bình_thuận đặc_biệt lưu_ý bệnh_nhân thứ <num>                                        \n",
              "958   theo đó ca bệnh <num> bệnh_nhân <num> là nam <num> tuổi tân_bình thành_phố hải_dương                 \n",
              "3208  bệnh_nhân <num> tuổi ở mumbai trở về từ dubai ngày <num> - <num>                                     \n",
              "3407  bệnh_viện bệnh nhiệt_đới tp hcm xét_nghiệm dương_tính lần một đêm <num>/<num>                        \n",
              "2366  hiện bệnh_nhân cũng điều_trị tại bệnh_viện bệnh nhiệt_đới trung_ương cơ_sở <num>                     \n",
              "634   bệnh_nhân <num> là nữ <num> tuổi ở q. <num> tp.hcm.                                                  \n",
              "4070  bà được xét_nghiệm dương_tính với virus corona chủng mới ngày <num> - <num>                          \n",
              "1863  bộ y_tế vừa xác_nhận bệnh_nhân covid - <num> thứ <num>                                               \n",
              "1821  bệnh_nhân <num> nam <num> tuổi ở bình_giang hải_dương                                                \n",
              "1771  bệnh_nhân <num> nữ <num> tuổi ở phúc_lợi long_biên sống và làm_việc tại mỹ                           \n",
              "1983  tại đây cụ được lấy mẫu xét_nghiệm kết_quả dương_tính ncov được ghi_nhận bệnh_nhân <num>             \n",
              "\n",
              "                                                                                        word  \\\n",
              "idx                                                                                            \n",
              "3752  Bệnh_nhân 622 nữ 39 tuổi trú thị_trấn Đông_Phú huyện Quế_Sơn làm nghề buôn_bán           \n",
              "4544  Đây là em bé thứ ba dưới một tuổi tại Việt_Nam nhiễm nCoV                                \n",
              "4713  Hai bệnh_nhân 684 749 đi nhiều nơi gặp nhiều người trên địa_bàn tỉnh Thừa_Thiên_Huế      \n",
              "5018  Người ra viện cuối_cùng ở Đà_Nẵng là bệnh_nhân 936                                       \n",
              "130   Ngày 28/7 bệnh_nhân đến trung_tâm y_tế huyện Quế_Sơn khám chụp phim điều_trị ngoại_trú   \n",
              "3261  Ngày 24/3 mẫu bệnh_phẩm được Viện Vệ_sinh Dịch_tễ Trung_ương xét_nghiệm khẳng_định       \n",
              "4587  Kết_quả xét_nghiệm ban_đầu có 11 mẫu âm_tính và nghi_ngờ dương_tính 1 mẫu                \n",
              "887   Ngày 2 - 4 bà khởi_phát bệnh                                                             \n",
              "5026  Ngày 12/8 anh được cách_ly tập_trung ngày 20/8 lấy mẫu xét_nghiệm kết_quả nghi nhiễm     \n",
              "4479  Ông Sơn đề_nghị Bình_Thuận đặc_biệt lưu_ý bệnh_nhân thứ 34                               \n",
              "958   Theo đó ca bệnh 963 bệnh_nhân 963 là nam 30 tuổi Tân_Bình thành_phố Hải_Dương            \n",
              "3208  Bệnh_nhân 64 tuổi ở Mumbai trở về từ Dubai ngày 8 - 3                                    \n",
              "3407  Bệnh_viện Bệnh Nhiệt_đới TP HCM xét_nghiệm dương_tính lần một đêm 12/3                   \n",
              "2366  Hiện bệnh_nhân cũng điều_trị tại Bệnh_viện Bệnh Nhiệt_đới Trung_ương cơ_sở 2             \n",
              "634   Bệnh_nhân 96 là nữ 21 tuổi ở Q. 8 TP.HCM.                                                \n",
              "4070  Bà được xét_nghiệm dương_tính với virus corona chủng mới ngày 28 - 3                     \n",
              "1863  Bộ Y_tế vừa xác_nhận bệnh_nhân COVID - 19 thứ 34                                         \n",
              "1821  Bệnh_nhân 867 nam 63 tuổi ở Bình_Giang Hải_Dương                                         \n",
              "1771  Bệnh_nhân 222 nữ 28 tuổi ở Phúc_Lợi Long_Biên sống và làm_việc tại Mỹ                    \n",
              "1983  Tại đây cụ được lấy mẫu xét_nghiệm kết_quả dương_tính nCoV được ghi_nhận bệnh_nhân 592   \n",
              "\n",
              "                                                                                                          tag  \\\n",
              "idx                                                                                                             \n",
              "3752  [O, B-PATIENT_ID, B-GENDER, B-AGE, O, O, B-LOCATION, I-LOCATION, B-LOCATION, I-LOCATION, O, O, B-JOB]     \n",
              "4544  [O, O, O, O, O, O, O, O, O, O, B-LOCATION, O, O]                                                          \n",
              "4713  [O, O, B-PATIENT_ID, B-PATIENT_ID, O, O, O, O, O, O, O, O, B-LOCATION, I-LOCATION]                        \n",
              "5018  [O, O, O, O, O, B-LOCATION, O, O, B-PATIENT_ID]                                                           \n",
              "130   [O, B-DATE, O, O, B-LOCATION, I-LOCATION, I-LOCATION, I-LOCATION, O, O, O, O, O]                          \n",
              "3261  [O, B-DATE, O, O, O, B-ORGANIZATION, I-ORGANIZATION, I-ORGANIZATION, I-ORGANIZATION, O, O]                \n",
              "4587  [O, O, O, O, O, O, O, O, O, O, O, O]                                                                      \n",
              "887   [O, B-DATE, I-DATE, I-DATE, O, O, O]                                                                      \n",
              "5026  [O, B-DATE, O, O, O, O, O, B-DATE, O, O, O, O, O, O]                                                      \n",
              "4479  [O, O, O, B-LOCATION, O, O, O, O, B-PATIENT_ID]                                                           \n",
              "958   [O, O, O, O, B-PATIENT_ID, O, B-PATIENT_ID, O, B-GENDER, B-AGE, O, B-LOCATION, B-LOCATION, I-LOCATION]    \n",
              "3208  [O, O, O, O, B-LOCATION, O, O, O, B-LOCATION, O, B-DATE, I-DATE, I-DATE]                                  \n",
              "3407  [B-ORGANIZATION, I-ORGANIZATION, I-ORGANIZATION, I-ORGANIZATION, I-ORGANIZATION, O, O, O, O, O, B-DATE]   \n",
              "2366  [O, O, O, O, O, B-LOCATION, I-LOCATION, I-LOCATION, I-LOCATION, I-LOCATION, I-LOCATION]                   \n",
              "634   [O, B-PATIENT_ID, O, B-GENDER, B-AGE, O, O, B-LOCATION, I-LOCATION, B-LOCATION]                           \n",
              "4070  [O, O, O, O, O, O, O, O, O, O, B-DATE, I-DATE, I-DATE]                                                    \n",
              "1863  [B-ORGANIZATION, I-ORGANIZATION, O, O, O, O, O, O, O, B-PATIENT_ID]                                       \n",
              "1821  [O, B-PATIENT_ID, B-GENDER, B-AGE, O, O, B-LOCATION, B-LOCATION]                                          \n",
              "1771  [O, B-PATIENT_ID, B-GENDER, B-AGE, O, O, B-LOCATION, B-LOCATION, O, O, O, O, B-LOCATION]                  \n",
              "1983  [O, O, O, O, O, O, O, O, O, O, O, O, O, B-PATIENT_ID]                                                     \n",
              "\n",
              "      len_tag  \n",
              "idx            \n",
              "3752  13       \n",
              "4544  13       \n",
              "4713  14       \n",
              "5018  9        \n",
              "130   13       \n",
              "3261  11       \n",
              "4587  12       \n",
              "887   7        \n",
              "5026  14       \n",
              "4479  9        \n",
              "958   14       \n",
              "3208  13       \n",
              "3407  11       \n",
              "2366  11       \n",
              "634   10       \n",
              "4070  13       \n",
              "1863  10       \n",
              "1821  8        \n",
              "1771  13       \n",
              "1983  14       "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f187500c-16cb-4278-944b-d551dee61c3e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word_process</th>\n",
              "      <th>word</th>\n",
              "      <th>tag</th>\n",
              "      <th>len_tag</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>idx</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3752</th>\n",
              "      <td>bệnh_nhân &lt;num&gt; nữ &lt;num&gt; tuổi trú thị_trấn đông_phú huyện quế_sơn làm nghề buôn_bán</td>\n",
              "      <td>Bệnh_nhân 622 nữ 39 tuổi trú thị_trấn Đông_Phú huyện Quế_Sơn làm nghề buôn_bán</td>\n",
              "      <td>[O, B-PATIENT_ID, B-GENDER, B-AGE, O, O, B-LOCATION, I-LOCATION, B-LOCATION, I-LOCATION, O, O, B-JOB]</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4544</th>\n",
              "      <td>đây là em bé thứ ba dưới một tuổi tại việt_nam nhiễm ncov</td>\n",
              "      <td>Đây là em bé thứ ba dưới một tuổi tại Việt_Nam nhiễm nCoV</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, B-LOCATION, O, O]</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4713</th>\n",
              "      <td>hai bệnh_nhân &lt;num&gt; &lt;num&gt; đi nhiều nơi gặp nhiều người trên địa_bàn tỉnh thừa_thiên_huế</td>\n",
              "      <td>Hai bệnh_nhân 684 749 đi nhiều nơi gặp nhiều người trên địa_bàn tỉnh Thừa_Thiên_Huế</td>\n",
              "      <td>[O, O, B-PATIENT_ID, B-PATIENT_ID, O, O, O, O, O, O, O, O, B-LOCATION, I-LOCATION]</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5018</th>\n",
              "      <td>người ra viện cuối_cùng ở đà_nẵng là bệnh_nhân &lt;num&gt;</td>\n",
              "      <td>Người ra viện cuối_cùng ở Đà_Nẵng là bệnh_nhân 936</td>\n",
              "      <td>[O, O, O, O, O, B-LOCATION, O, O, B-PATIENT_ID]</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130</th>\n",
              "      <td>ngày &lt;num&gt;/&lt;num&gt; bệnh_nhân đến trung_tâm y_tế huyện quế_sơn khám chụp phim điều_trị ngoại_trú</td>\n",
              "      <td>Ngày 28/7 bệnh_nhân đến trung_tâm y_tế huyện Quế_Sơn khám chụp phim điều_trị ngoại_trú</td>\n",
              "      <td>[O, B-DATE, O, O, B-LOCATION, I-LOCATION, I-LOCATION, I-LOCATION, O, O, O, O, O]</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3261</th>\n",
              "      <td>ngày &lt;num&gt;/&lt;num&gt; mẫu bệnh_phẩm được viện vệ_sinh dịch_tễ trung_ương xét_nghiệm khẳng_định</td>\n",
              "      <td>Ngày 24/3 mẫu bệnh_phẩm được Viện Vệ_sinh Dịch_tễ Trung_ương xét_nghiệm khẳng_định</td>\n",
              "      <td>[O, B-DATE, O, O, O, B-ORGANIZATION, I-ORGANIZATION, I-ORGANIZATION, I-ORGANIZATION, O, O]</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4587</th>\n",
              "      <td>kết_quả xét_nghiệm ban_đầu có &lt;num&gt; mẫu âm_tính và nghi_ngờ dương_tính &lt;num&gt; mẫu</td>\n",
              "      <td>Kết_quả xét_nghiệm ban_đầu có 11 mẫu âm_tính và nghi_ngờ dương_tính 1 mẫu</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>ngày &lt;num&gt; - &lt;num&gt; bà khởi_phát bệnh</td>\n",
              "      <td>Ngày 2 - 4 bà khởi_phát bệnh</td>\n",
              "      <td>[O, B-DATE, I-DATE, I-DATE, O, O, O]</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5026</th>\n",
              "      <td>ngày &lt;num&gt;/&lt;num&gt; anh được cách_ly tập_trung ngày &lt;num&gt;/&lt;num&gt; lấy mẫu xét_nghiệm kết_quả nghi nhiễm</td>\n",
              "      <td>Ngày 12/8 anh được cách_ly tập_trung ngày 20/8 lấy mẫu xét_nghiệm kết_quả nghi nhiễm</td>\n",
              "      <td>[O, B-DATE, O, O, O, O, O, B-DATE, O, O, O, O, O, O]</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4479</th>\n",
              "      <td>ông sơn đề_nghị bình_thuận đặc_biệt lưu_ý bệnh_nhân thứ &lt;num&gt;</td>\n",
              "      <td>Ông Sơn đề_nghị Bình_Thuận đặc_biệt lưu_ý bệnh_nhân thứ 34</td>\n",
              "      <td>[O, O, O, B-LOCATION, O, O, O, O, B-PATIENT_ID]</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>958</th>\n",
              "      <td>theo đó ca bệnh &lt;num&gt; bệnh_nhân &lt;num&gt; là nam &lt;num&gt; tuổi tân_bình thành_phố hải_dương</td>\n",
              "      <td>Theo đó ca bệnh 963 bệnh_nhân 963 là nam 30 tuổi Tân_Bình thành_phố Hải_Dương</td>\n",
              "      <td>[O, O, O, O, B-PATIENT_ID, O, B-PATIENT_ID, O, B-GENDER, B-AGE, O, B-LOCATION, B-LOCATION, I-LOCATION]</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3208</th>\n",
              "      <td>bệnh_nhân &lt;num&gt; tuổi ở mumbai trở về từ dubai ngày &lt;num&gt; - &lt;num&gt;</td>\n",
              "      <td>Bệnh_nhân 64 tuổi ở Mumbai trở về từ Dubai ngày 8 - 3</td>\n",
              "      <td>[O, O, O, O, B-LOCATION, O, O, O, B-LOCATION, O, B-DATE, I-DATE, I-DATE]</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3407</th>\n",
              "      <td>bệnh_viện bệnh nhiệt_đới tp hcm xét_nghiệm dương_tính lần một đêm &lt;num&gt;/&lt;num&gt;</td>\n",
              "      <td>Bệnh_viện Bệnh Nhiệt_đới TP HCM xét_nghiệm dương_tính lần một đêm 12/3</td>\n",
              "      <td>[B-ORGANIZATION, I-ORGANIZATION, I-ORGANIZATION, I-ORGANIZATION, I-ORGANIZATION, O, O, O, O, O, B-DATE]</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2366</th>\n",
              "      <td>hiện bệnh_nhân cũng điều_trị tại bệnh_viện bệnh nhiệt_đới trung_ương cơ_sở &lt;num&gt;</td>\n",
              "      <td>Hiện bệnh_nhân cũng điều_trị tại Bệnh_viện Bệnh Nhiệt_đới Trung_ương cơ_sở 2</td>\n",
              "      <td>[O, O, O, O, O, B-LOCATION, I-LOCATION, I-LOCATION, I-LOCATION, I-LOCATION, I-LOCATION]</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>634</th>\n",
              "      <td>bệnh_nhân &lt;num&gt; là nữ &lt;num&gt; tuổi ở q. &lt;num&gt; tp.hcm.</td>\n",
              "      <td>Bệnh_nhân 96 là nữ 21 tuổi ở Q. 8 TP.HCM.</td>\n",
              "      <td>[O, B-PATIENT_ID, O, B-GENDER, B-AGE, O, O, B-LOCATION, I-LOCATION, B-LOCATION]</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4070</th>\n",
              "      <td>bà được xét_nghiệm dương_tính với virus corona chủng mới ngày &lt;num&gt; - &lt;num&gt;</td>\n",
              "      <td>Bà được xét_nghiệm dương_tính với virus corona chủng mới ngày 28 - 3</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, B-DATE, I-DATE, I-DATE]</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1863</th>\n",
              "      <td>bộ y_tế vừa xác_nhận bệnh_nhân covid - &lt;num&gt; thứ &lt;num&gt;</td>\n",
              "      <td>Bộ Y_tế vừa xác_nhận bệnh_nhân COVID - 19 thứ 34</td>\n",
              "      <td>[B-ORGANIZATION, I-ORGANIZATION, O, O, O, O, O, O, O, B-PATIENT_ID]</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1821</th>\n",
              "      <td>bệnh_nhân &lt;num&gt; nam &lt;num&gt; tuổi ở bình_giang hải_dương</td>\n",
              "      <td>Bệnh_nhân 867 nam 63 tuổi ở Bình_Giang Hải_Dương</td>\n",
              "      <td>[O, B-PATIENT_ID, B-GENDER, B-AGE, O, O, B-LOCATION, B-LOCATION]</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1771</th>\n",
              "      <td>bệnh_nhân &lt;num&gt; nữ &lt;num&gt; tuổi ở phúc_lợi long_biên sống và làm_việc tại mỹ</td>\n",
              "      <td>Bệnh_nhân 222 nữ 28 tuổi ở Phúc_Lợi Long_Biên sống và làm_việc tại Mỹ</td>\n",
              "      <td>[O, B-PATIENT_ID, B-GENDER, B-AGE, O, O, B-LOCATION, B-LOCATION, O, O, O, O, B-LOCATION]</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1983</th>\n",
              "      <td>tại đây cụ được lấy mẫu xét_nghiệm kết_quả dương_tính ncov được ghi_nhận bệnh_nhân &lt;num&gt;</td>\n",
              "      <td>Tại đây cụ được lấy mẫu xét_nghiệm kết_quả dương_tính nCoV được ghi_nhận bệnh_nhân 592</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, B-PATIENT_ID]</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f187500c-16cb-4278-944b-d551dee61c3e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f187500c-16cb-4278-944b-d551dee61c3e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f187500c-16cb-4278-944b-d551dee61c3e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0c942419-a850-4ee9-b514-2d15308b1cdf\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0c942419-a850-4ee9-b514-2d15308b1cdf')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0c942419-a850-4ee9-b514-2d15308b1cdf button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "word_train_data_group[word_train_data_group['len_tag'] < 15].sample(20)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count_B_AGE = word_test_data_group['tag'].apply(lambda x: x.count('B-AGE')).sum()\n",
        "print(count_B_AGE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GG0knH9kEwOV",
        "outputId": "96619320-8130-4226-a0ad-838963b91fc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "582\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItK-M8iLuiZG"
      },
      "source": [
        "#CRF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RIKRa5zLuhxQ"
      },
      "outputs": [],
      "source": [
        "class CRF(L.Layer):\n",
        "    def __init__(self,\n",
        "                 output_dim,\n",
        "                 sparse_target=True,\n",
        "                 **kwargs):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            output_dim (int): the number of labels to tag each temporal input.\n",
        "            sparse_target (bool): whether the the ground-truth label represented in one-hot.\n",
        "        Input shape:\n",
        "            (batch_size, sentence length, output_dim)\n",
        "        Output shape:\n",
        "            (batch_size, sentence length, output_dim)\n",
        "        \"\"\"\n",
        "        super(CRF, self).__init__(**kwargs)\n",
        "        self.output_dim = int(output_dim)\n",
        "        self.sparse_target = sparse_target\n",
        "        self.input_spec = L.InputSpec(min_ndim=3)\n",
        "        self.supports_masking = False\n",
        "        self.sequence_lengths = None\n",
        "        self.transitions = None\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) == 3\n",
        "        f_shape = tf.TensorShape(input_shape)\n",
        "        input_spec = L.InputSpec(min_ndim=3, axes={-1: f_shape[-1]})\n",
        "\n",
        "        if f_shape[-1] is None:\n",
        "            raise ValueError('The last dimension of the inputs to `CRF` '\n",
        "                             'should be defined. Found `None`.')\n",
        "        if f_shape[-1] != self.output_dim:\n",
        "            raise ValueError('The last dimension of the input shape must be equal to output'\n",
        "                             ' shape. Use a linear layer if needed.')\n",
        "        self.input_spec = input_spec\n",
        "        self.transitions = self.add_weight(name='transitions',\n",
        "                                           shape=[self.output_dim, self.output_dim],\n",
        "                                           initializer='glorot_uniform',\n",
        "                                           trainable=True)\n",
        "        self.built = True\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        # Just pass the received mask from previous layer, to the next layer or\n",
        "        # manipulate it if this layer changes the shape of the input\n",
        "        return mask\n",
        "\n",
        "    def call(self, inputs, sequence_lengths=None, training=None, **kwargs):\n",
        "        sequences = tf.convert_to_tensor(inputs, dtype=self.dtype)\n",
        "        if sequence_lengths is not None:\n",
        "            assert len(sequence_lengths.shape) == 2\n",
        "            assert tf.convert_to_tensor(sequence_lengths).dtype == 'int32'\n",
        "            seq_len_shape = tf.convert_to_tensor(sequence_lengths).get_shape().as_list()\n",
        "            assert seq_len_shape[1] == 1\n",
        "            self.sequence_lengths = K.flatten(sequence_lengths)\n",
        "        else:\n",
        "            self.sequence_lengths = tf.ones(tf.shape(inputs)[0], dtype=tf.int32) * (\n",
        "                tf.shape(inputs)[1]\n",
        "            )\n",
        "\n",
        "        viterbi_sequence, _ = crf_decode(sequences,\n",
        "                                         self.transitions,\n",
        "                                         self.sequence_lengths)\n",
        "        output = K.one_hot(viterbi_sequence, self.output_dim)\n",
        "        return K.in_train_phase(sequences, output)\n",
        "\n",
        "    @property\n",
        "    def loss(self):\n",
        "        def crf_loss(y_true, y_pred):\n",
        "            y_pred = tf.convert_to_tensor(y_pred, dtype=self.dtype)\n",
        "            log_likelihood, self.transitions = crf_log_likelihood(\n",
        "                y_pred,\n",
        "                tf.cast(K.argmax(y_true), dtype=tf.int32) if self.sparse_target else y_true,\n",
        "                self.sequence_lengths,\n",
        "                transition_params=self.transitions,\n",
        "            )\n",
        "            return tf.reduce_mean(-log_likelihood)\n",
        "        return crf_loss\n",
        "\n",
        "    @property\n",
        "    def accuracy(self):\n",
        "        def viterbi_accuracy(y_true, y_pred):\n",
        "            # -1e10 to avoid zero at sum(mask)\n",
        "            mask = K.cast(\n",
        "                K.all(K.greater(y_pred, -1e10), axis=2), K.floatx())\n",
        "            shape = tf.shape(y_pred)\n",
        "            sequence_lengths = tf.ones(shape[0], dtype=tf.int32) * (shape[1])\n",
        "            y_pred, _ = crf_decode(y_pred, self.transitions, sequence_lengths)\n",
        "            if self.sparse_target:\n",
        "                y_true = K.argmax(y_true, 2)\n",
        "            y_pred = K.cast(y_pred, 'int32')\n",
        "            y_true = K.cast(y_true, 'int32')\n",
        "            corrects = K.cast(K.equal(y_true, y_pred), K.floatx())\n",
        "            return K.sum(corrects * mask) / K.sum(mask)\n",
        "        return viterbi_accuracy\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        tf.TensorShape(input_shape).assert_has_rank(3)\n",
        "        return input_shape[:2] + (self.output_dim,)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'output_dim': self.output_dim,\n",
        "            'sparse_target': self.sparse_target,\n",
        "            'supports_masking': self.supports_masking,\n",
        "            'transitions': K.eval(self.transitions)\n",
        "        }\n",
        "        base_config = super(CRF, self).get_config()\n",
        "        return dict(base_config, **config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDy9K8TiXoFi"
      },
      "source": [
        "# FastText"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjtK4XxMXQsu"
      },
      "outputs": [],
      "source": [
        "word_trained = False\n",
        "syll_trained = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zPPAue7MhI0e"
      },
      "outputs": [],
      "source": [
        "def train_model_fasttext(train_data, size=100, window=5, min_count=3, negative=5, sg=1, alpha=0.01, epoch=50):\n",
        "    train_data = [each.split() for each in train_data]\n",
        "    model_fasttext = FastText(vector_size=size, window=window, min_count=min_count,\n",
        "                              workers=4, sg=1, negative=negative, alpha=alpha)\n",
        "    model_fasttext.build_vocab(train_data)\n",
        "    model_fasttext.train(train_data, total_examples=model_fasttext.corpus_count, epochs=epoch)\n",
        "    return model_fasttext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Stxhegaaegt8"
      },
      "outputs": [],
      "source": [
        "if word_trained:\n",
        "    word_md = FastText.load('word_model_fasttext_gensim.bin')\n",
        "else:\n",
        "    word_md = train_model_fasttext([*word_train_data_group['word_process'],\n",
        "                                    *word_val_data_group['word_process']],\n",
        "                                    epoch=50, window=5)\n",
        "    word_md.save('word_model_fasttext_gensim.bin')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QiQBaFuzI-X9"
      },
      "outputs": [],
      "source": [
        "word_tokenizer = Tokenizer(num_words=len(word_md.wv.key_to_index), lower=True, filters=\"\", oov_token='-OOV-')\n",
        "word_tokenizer.fit_on_texts([*word_train_data_group['word_process'], *word_val_data_group['word_process']])\n",
        "word_index = word_tokenizer.word_index\n",
        "emb_mean, emb_std = -0.5,0.5\n",
        "embed_size = 100\n",
        "nb_words = len(word_index) + 1\n",
        "word_embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
        "for word, i in word_index.items():\n",
        "    if i >= nb_words:\n",
        "        continue\n",
        "    if word in word_md.wv.key_to_index:\n",
        "        word_embedding_matrix[i] = word_md.wv.get_vector(word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZlUnAUjjLAPs"
      },
      "outputs": [],
      "source": [
        "word_max_length = 200\n",
        "word_X_train = word_tokenizer.texts_to_sequences(word_train_data_group['word_process'])\n",
        "word_X_val = word_tokenizer.texts_to_sequences(word_val_data_group['word_process'])\n",
        "word_X_test = word_tokenizer.texts_to_sequences(word_test_data_group['word_process'])\n",
        "\n",
        "word_X_train = pad_sequences(word_X_train, maxlen=word_max_length, padding='post')\n",
        "word_X_val = pad_sequences(word_X_val, maxlen=word_max_length, padding='post')\n",
        "word_X_test = pad_sequences(word_X_test, maxlen=word_max_length, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jj_kbJH0L-6Z"
      },
      "outputs": [],
      "source": [
        "word_tag_tokenizer = Tokenizer(filters=\"\", lower=False)\n",
        "word_tag_tokenizer.fit_on_texts(word_train_data_group['tag'].apply(lambda x: ' '.join(x)))\n",
        "word_tag_index = word_tag_tokenizer.word_index\n",
        "word_tag_size = len(word_tag_index)+1\n",
        "\n",
        "word_y_train = word_tag_tokenizer.texts_to_sequences(word_train_data_group['tag'].apply(lambda x: ' '.join(x)))\n",
        "word_y_val = word_tag_tokenizer.texts_to_sequences(word_val_data_group['tag'].apply(lambda x: ' '.join(x)))\n",
        "word_y_test = word_tag_tokenizer.texts_to_sequences(word_test_data_group['tag'].apply(lambda x: ' '.join(x)))\n",
        "\n",
        "word_y_train = pad_sequences(word_y_train, maxlen=word_max_length, padding='post')\n",
        "word_y_val = pad_sequences(word_y_val, maxlen=word_max_length, padding='post')\n",
        "word_y_test = pad_sequences(word_y_test, maxlen=word_max_length, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wUDYx-ylP7Mc"
      },
      "outputs": [],
      "source": [
        "word_y_train = np.asarray([to_categorical(i, num_classes=word_tag_size) for i in word_y_train])\n",
        "word_y_val = np.asarray([to_categorical(i, num_classes=word_tag_size) for i in word_y_val])\n",
        "word_y_test = np.asarray([to_categorical(i, num_classes=word_tag_size) for i in word_y_test])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x003rxWDK-tm"
      },
      "source": [
        "#MODEL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKWWYXQXBbVQ"
      },
      "source": [
        "## Without CRF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mev2zNb6bL46"
      },
      "outputs": [],
      "source": [
        "def create_model(embeddings_matrix, vocab_size, embedding_dim, max_length):\n",
        "    input = Input(shape = (max_length, ), dtype='int32', name='input_text')\n",
        "    x = Embedding(input_dim=vocab_size, output_dim=embedding_dim,\n",
        "                  weights=[word_embedding_matrix])(input)\n",
        "    x = Bidirectional(LSTM(units=max_length, return_sequences=True,\n",
        "                                recurrent_dropout=0.01))(x)\n",
        "    x = TimeDistributed(Dense(128, activation='relu', kernel_initializer='he_normal'))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(rate=0.5)(x)\n",
        "    output = Dense(word_tag_size, activation='softmax', kernel_initializer='he_normal')(x)\n",
        "    model_final = Model(input, output)\n",
        "    model_final.compile(optimizer=Optimizer.Adam(lr=0.005), loss='categorical_crossentropy',\n",
        "                        metrics=['accuracy'])\n",
        "    return model_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjf56fmOBe1x",
        "outputId": "7cf0a611-ea12-4578-f228-9ba4e1dd75ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_text (InputLayer)     [(None, 200)]             0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 200, 100)          451700    \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 200, 400)          481600    \n",
            " al)                                                             \n",
            "                                                                 \n",
            " time_distributed (TimeDist  (None, 200, 128)          51328     \n",
            " ributed)                                                        \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 200, 128)          512       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 200, 128)          0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 200, 21)           2709      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 987849 (3.77 MB)\n",
            "Trainable params: 987593 (3.77 MB)\n",
            "Non-trainable params: 256 (1.00 KB)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "model = create_model(word_embedding_matrix, nb_words, embed_size, word_max_length)\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZocSoblnBe1z",
        "outputId": "2563e347-040c-40bf-a089-168aecaf17df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "79/79 [==============================] - 146s 2s/step - loss: 0.5742 - accuracy: 0.9300 - val_loss: 0.2430 - val_accuracy: 0.9664\n",
            "Epoch 2/10\n",
            "79/79 [==============================] - 130s 2s/step - loss: 0.1142 - accuracy: 0.9785 - val_loss: 0.2025 - val_accuracy: 0.9776\n",
            "Epoch 3/10\n",
            "79/79 [==============================] - 124s 2s/step - loss: 0.0588 - accuracy: 0.9866 - val_loss: 0.1341 - val_accuracy: 0.9875\n",
            "Epoch 4/10\n",
            "79/79 [==============================] - 125s 2s/step - loss: 0.0376 - accuracy: 0.9907 - val_loss: 0.1372 - val_accuracy: 0.9890\n",
            "Epoch 5/10\n",
            "79/79 [==============================] - 125s 2s/step - loss: 0.0275 - accuracy: 0.9931 - val_loss: 0.0619 - val_accuracy: 0.9918\n",
            "Epoch 6/10\n",
            "79/79 [==============================] - 122s 2s/step - loss: 0.0221 - accuracy: 0.9942 - val_loss: 0.0416 - val_accuracy: 0.9928\n",
            "Epoch 7/10\n",
            "79/79 [==============================] - 123s 2s/step - loss: 0.0182 - accuracy: 0.9952 - val_loss: 0.0528 - val_accuracy: 0.9935\n",
            "Epoch 8/10\n",
            "79/79 [==============================] - 126s 2s/step - loss: 0.0158 - accuracy: 0.9957 - val_loss: 0.0250 - val_accuracy: 0.9937\n",
            "Epoch 9/10\n",
            "79/79 [==============================] - 123s 2s/step - loss: 0.0142 - accuracy: 0.9960 - val_loss: 0.0249 - val_accuracy: 0.9937\n",
            "Epoch 10/10\n",
            "79/79 [==============================] - 125s 2s/step - loss: 0.0126 - accuracy: 0.9965 - val_loss: 0.0253 - val_accuracy: 0.9938\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c78d1522500>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "model.fit(word_X_train, word_y_train, batch_size=64, epochs=10, validation_data = (word_X_val, word_y_val), verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3eV2raUUBe1z"
      },
      "outputs": [],
      "source": [
        "def get_tags(sequences, tag_index):\n",
        "    sequence_tags = []\n",
        "    for sequence in sequences:\n",
        "        sequence_tag = []\n",
        "        for categorical in sequence:\n",
        "            sequence_tag.append(tag_index.get(np.argmax(categorical)))\n",
        "        sequence_tags.append(sequence_tag)\n",
        "    return sequence_tags\n",
        "\n",
        "def predict(model, tag_tokenizer, sent):\n",
        "    tag_index = tag_tokenizer.word_index\n",
        "    tag_size = len(tag_index) + 1\n",
        "    pred = model.predict(sent)\n",
        "    sequence_tags = get_tags(pred, {i: t for t, i in tag_index.items()})\n",
        "    for idx, each in enumerate(sequence_tags):\n",
        "        try:\n",
        "           idx_cut = each.index(None)\n",
        "        except:\n",
        "           idx_cut = len(each) + 1\n",
        "        sequence_tags[idx] = each[:idx_cut]\n",
        "    return sequence_tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lWpy9c9Be10",
        "outputId": "a2bf1767-6f1d-4cc9-eac0-ea4f8d5f9a1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94/94 [==============================] - 11s 111ms/step\n",
            "                     precision    recall  f1-score   support\n",
            "\n",
            "                AGE       0.90      0.88      0.89       582\n",
            "               DATE       0.94      0.95      0.94      1654\n",
            "             GENDER       0.95      0.85      0.90       462\n",
            "                JOB       0.53      0.24      0.33       173\n",
            "           LOCATION       0.80      0.76      0.78      4441\n",
            "               NAME       0.93      0.43      0.59       318\n",
            "       ORGANIZATION       0.65      0.65      0.65       771\n",
            "         PATIENT_ID       0.97      0.94      0.95      2005\n",
            "SYMPTOM_AND_DISEASE       0.70      0.61      0.65      1136\n",
            "     TRANSPORTATION       0.92      0.79      0.85       193\n",
            "\n",
            "          micro avg       0.84      0.79      0.81     11735\n",
            "          macro avg       0.83      0.71      0.75     11735\n",
            "       weighted avg       0.84      0.79      0.81     11735\n",
            "\n"
          ]
        }
      ],
      "source": [
        "res = predict(model, word_tag_tokenizer, word_X_test)\n",
        "print(classification_report(word_test_data_group['tag'].apply(lambda x: x[:word_max_length]), res))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PE2NdqK5TG-"
      },
      "source": [
        "## With CRF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdZ48UTM5HQl"
      },
      "outputs": [],
      "source": [
        "def create_model_crf(embeddings_matrix, vocab_size, embedding_dim, max_length):\n",
        "    input = Input(shape = (max_length, ), dtype='int32', name='input_text')\n",
        "    x = Embedding(input_dim=vocab_size, output_dim=embedding_dim,\n",
        "                  weights=[word_embedding_matrix])(input)\n",
        "    x = Bidirectional(LSTM(units=max_length, return_sequences=True,\n",
        "                                recurrent_dropout=0.01))(x)\n",
        "    x = TimeDistributed(Dense(128, activation='relu', kernel_initializer='he_normal'))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(rate=0.5)(x)\n",
        "    x = Dense(word_tag_size, activation='relu', kernel_initializer='he_normal')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(rate=0.1)(x)\n",
        "    crf = CRF(word_tag_size)\n",
        "    output = crf(x)\n",
        "    model_final = Model(input, output)\n",
        "    model_final.compile(optimizer=Optimizer.Adam(lr=0.005), loss=crf.loss,\n",
        "                        metrics=[crf.accuracy])\n",
        "\n",
        "    return model_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFgLImwSfvLt",
        "outputId": "0f48fa8e-7fbc-47b7-fa06-321f71127e60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_text (InputLayer)     [(None, 200)]             0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 200, 100)          451700    \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 200, 400)          481600    \n",
            " al)                                                             \n",
            "                                                                 \n",
            " time_distributed (TimeDist  (None, 200, 128)          51328     \n",
            " ributed)                                                        \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 200, 128)          512       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 200, 128)          0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 200, 21)           2709      \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 200, 21)           84        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 200, 21)           0         \n",
            "                                                                 \n",
            " crf (CRF)                   (None, 200, 21)           441       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 988374 (3.77 MB)\n",
            "Trainable params: 988076 (3.77 MB)\n",
            "Non-trainable params: 298 (1.16 KB)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "model = create_model_crf(word_embedding_matrix, nb_words, embed_size, word_max_length)\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlSyWhtUJfpT",
        "outputId": "0b27c407-4295-4639-8262-21dd7255307b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "79/79 [==============================] - 160s 2s/step - loss: 527.3000 - viterbi_accuracy: 0.4764 - val_loss: 440.0032 - val_viterbi_accuracy: 0.9408\n",
            "Epoch 2/10\n",
            "79/79 [==============================] - 150s 2s/step - loss: 430.5999 - viterbi_accuracy: 0.7827 - val_loss: 581.1432 - val_viterbi_accuracy: 0.0974\n",
            "Epoch 3/10\n",
            "79/79 [==============================] - 133s 2s/step - loss: 363.6150 - viterbi_accuracy: 0.9509 - val_loss: 552.0652 - val_viterbi_accuracy: 0.0999\n",
            "Epoch 4/10\n",
            "79/79 [==============================] - 146s 2s/step - loss: 303.7389 - viterbi_accuracy: 0.9799 - val_loss: 523.3336 - val_viterbi_accuracy: 0.1007\n",
            "Epoch 5/10\n",
            "79/79 [==============================] - 140s 2s/step - loss: 248.4680 - viterbi_accuracy: 0.9827 - val_loss: 495.6163 - val_viterbi_accuracy: 0.1018\n",
            "Epoch 6/10\n",
            "79/79 [==============================] - 142s 2s/step - loss: 197.8174 - viterbi_accuracy: 0.9840 - val_loss: 469.8744 - val_viterbi_accuracy: 0.0956\n",
            "Epoch 7/10\n",
            "79/79 [==============================] - 131s 2s/step - loss: 153.0242 - viterbi_accuracy: 0.9850 - val_loss: 446.1805 - val_viterbi_accuracy: 0.0908\n",
            "Epoch 8/10\n",
            "79/79 [==============================] - 130s 2s/step - loss: 115.0990 - viterbi_accuracy: 0.9857 - val_loss: 424.7689 - val_viterbi_accuracy: 0.0860\n",
            "Epoch 9/10\n",
            "79/79 [==============================] - 143s 2s/step - loss: 84.3953 - viterbi_accuracy: 0.9869 - val_loss: 406.3819 - val_viterbi_accuracy: 0.0847\n",
            "Epoch 10/10\n",
            "79/79 [==============================] - 138s 2s/step - loss: 63.8958 - viterbi_accuracy: 0.9879 - val_loss: 391.3575 - val_viterbi_accuracy: 0.0845\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e9b02f17730>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "model.fit(word_X_train, word_y_train, batch_size=64, epochs=10, validation_data = (word_X_val, word_y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sc7rRHC82rO_"
      },
      "outputs": [],
      "source": [
        "def get_tags(sequences, tag_index):\n",
        "    sequence_tags = []\n",
        "    for sequence in sequences:\n",
        "        sequence_tag = []\n",
        "        for categorical in sequence:\n",
        "            sequence_tag.append(tag_index.get(np.argmax(categorical)))\n",
        "        sequence_tags.append(sequence_tag)\n",
        "    return sequence_tags\n",
        "\n",
        "def predict(model, tag_tokenizer, sent):\n",
        "    tag_index = tag_tokenizer.word_index\n",
        "    tag_size = len(tag_index) + 1\n",
        "    pred = model.predict(sent)\n",
        "    sequence_tags = get_tags(pred, {i: t for t, i in tag_index.items()})\n",
        "    for idx, each in enumerate(sequence_tags):\n",
        "        try:\n",
        "           idx_cut = each.index(None)\n",
        "        except:\n",
        "           idx_cut = len(each) + 1\n",
        "        sequence_tags[idx] = each[:idx_cut]\n",
        "    return sequence_tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 737
        },
        "id": "C2s2jLFQ-FFL",
        "outputId": "3e1bec6a-5e7d-4f92-b874-a13f2c4fd394"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94/94 [==============================] - 23s 250ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-a275da541b4f>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_tag_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_X_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_test_data_group\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tag'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mword_max_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, digits, suffix, output_dict, mode, sample_weight, zero_division, scheme)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m     \u001b[0;31m# compute per-class scores.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m     p, r, f1, s = precision_recall_fscore_support(\n\u001b[0m\u001b[1;32m    693\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m         \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, average, warn_for, beta, sample_weight, zero_division, suffix)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpred_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtp_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_sum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     precision, recall, f_score, true_sum = _precision_recall_fscore_support(\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py\u001b[0m in \u001b[0;36m_precision_recall_fscore_support\u001b[0;34m(y_true, y_pred, average, warn_for, beta, sample_weight, zero_division, scheme, suffix, extract_tp_actual_correct)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'average has to be one of {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maverage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mpred_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtp_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_tp_actual_correct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheme\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen_true\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen_pred\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Found input variables with inconsistent numbers of samples:\\n{}\\n{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples:\n[41, 25, 47, 54, 17, 34, 16, 95, 47, 17, 21, 29, 12, 16, 18, 20, 22, 36, 19, 14, 24, 39, 19, 27, 57, 36, 10, 21, 15, 17, 62, 13, 34, 24, 24, 37, 62, 26, 21, 18, 22, 21, 24, 28, 31, 29, 37, 45, 74, 20, 31, 12, 12, 64, 30, 39, 37, 36, 27, 29, 21, 22, 25, 14, 15, 38, 39, 30, 25, 25, 18, 14, 24, 20, 31, 25, 37, 16, 26, 15, 24, 33, 27, 24, 14, 21, 51, 78, 33, 14, 18, 17, 12, 15, 48, 34, 37, 16, 24, 19, 42, 20, 15, 20, 46, 28, 36, 36, 22, 20, 21, 43, 17, 41, 26, 16, 20, 28, 24, 47, 20, 33, 21, 36, 13, 22, 16, 16, 36, 24, 30, 26, 20, 18, 20, 24, 23, 25, 40, 21, 7, 25, 27, 28, 31, 17, 45, 21, 24, 31, 19, 26, 16, 27, 26, 26, 10, 35, 17, 38, 44, 19, 27, 18, 11, 16, 21, 29, 22, 16, 26, 18, 20, 20, 55, 28, 24, 13, 34, 34, 21, 16, 18, 36, 14, 53, 14, 16, 24, 28, 35, 16, 36, 23, 22, 25, 21, 27, 25, 26, 21, 30, 21, 52, 26, 18, 27, 14, 36, 16, 23, 12, 22, 29, 21, 46, 28, 25, 31, 15, 25, 42, 16, 34, 121, 27, 31, 21, 30, 18, 20, 34, 35, 20, 28, 58, 39, 51, 15, 14, 39, 26, 23, 21, 15, 90, 12, 25, 36, 36, 37, 30, 13, 52, 20, 14, 7, 59, 30, 14, 28, 26, 10, 52, 13, 16, 31, 33, 9, 68, 39, 27, 20, 11, 42, 23, 54, 11, 43, 13, 37, 17, 25, 19, 33, 27, 24, 22, 29, 23, 13, 39, 29, 20, 33, 35, 18, 58, 21, 18, 25, 41, 51, 17, 63, 13, 16, 37, 24, 32, 24, 44, 47, 17, 12, 18, 29, 39, 37, 25, 24, 20, 29, 22, 28, 25, 24, 16, 74, 22, 13, 29, 27, 19, 47, 34, 54, 41, 17, 11, 25, 26, 8, 15, 32, 20, 29, 18, 47, 19, 33, 15, 31, 14, 20, 24, 30, 15, 17, 45, 42, 20, 19, 22, 13, 42, 14, 56, 19, 28, 18, 63, 47, 15, 26,...\n[200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 2..."
          ]
        }
      ],
      "source": [
        "res = predict(model, word_tag_tokenizer, word_X_test)\n",
        "print(classification_report(word_test_data_group['tag'].apply(lambda x: x[:word_max_length]), res))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights(\"BiLSTM_CRF/model\")"
      ],
      "metadata": {
        "id": "P4FWhnZDpj2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**evaluate**"
      ],
      "metadata": {
        "id": "AQxXU76AoJhH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_load = create_model_crf(word_embedding_matrix, nb_words, embed_size, word_max_length)\n",
        "model_load.load_weights(\"/content/BiLSTM_CRF/model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYeLmLbco1wl",
        "outputId": "c1f796f5-71f5-4144-9545-d2879a17d9ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7e9a460cf730>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = [\"Đồng_thời\", \",\", \"bệnh_viện\", \"tiếp_tục\", \"thực_hiện\", \"các\", \"biện_pháp\", \"phòng_chống\", \"dịch_bệnh\", \"COVID\", \"-\", \"19\", \"theo\", \"hướng_dẫn\", \"của\", \"Bộ\", \"Y_tế\", \".\"]\n",
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5y7B6nCXqTPl",
        "outputId": "7b28b22e-8bc5-43ff-f402-34587360c3f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Đồng_thời',\n",
              " ',',\n",
              " 'bệnh_viện',\n",
              " 'tiếp_tục',\n",
              " 'thực_hiện',\n",
              " 'các',\n",
              " 'biện_pháp',\n",
              " 'phòng_chống',\n",
              " 'dịch_bệnh',\n",
              " 'COVID',\n",
              " '-',\n",
              " '19',\n",
              " 'theo',\n",
              " 'hướng_dẫn',\n",
              " 'của',\n",
              " 'Bộ',\n",
              " 'Y_tế',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = word_tokenizer.texts_to_sequences(text)\n",
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wfdl1MRqkOV",
        "outputId": "6a713328-f8ab-4bbf-9c4f-359253fe814a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[463],\n",
              " [1],\n",
              " [8],\n",
              " [147],\n",
              " [254],\n",
              " [33],\n",
              " [516],\n",
              " [272],\n",
              " [391],\n",
              " [26],\n",
              " [4],\n",
              " [1],\n",
              " [73],\n",
              " [500],\n",
              " [32],\n",
              " [77],\n",
              " [29],\n",
              " [1]]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = predict(model_load, word_tag_tokenizer, text)\n",
        "res"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPXuHBaxqaQP",
        "outputId": "efa89eeb-8c03-42e5-fc8a-2773a8c20976"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 467ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['O'],\n",
              " ['O'],\n",
              " ['I-ORGANIZATION'],\n",
              " ['O'],\n",
              " ['O'],\n",
              " ['O'],\n",
              " ['O'],\n",
              " ['I-ORGANIZATION'],\n",
              " ['I-ORGANIZATION'],\n",
              " ['O'],\n",
              " ['I-DATE'],\n",
              " ['O'],\n",
              " ['O'],\n",
              " ['O'],\n",
              " ['O'],\n",
              " ['B-ORGANIZATION'],\n",
              " ['I-ORGANIZATION'],\n",
              " ['O']]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ie3imNlkq8zD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}